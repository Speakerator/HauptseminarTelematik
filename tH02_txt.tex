\documentclass{semdoc}
\usepackage{lipsum} 
\usepackage{xargs}           % Use more than one optional parameter in a new commands
\usepackage[pdftex,dvipsnames]{xcolor} % Coloured text etc.
\usepackage{textcomp}
\usepackage{listings}
%\usepackage{german}


%allow the use of the todo command 
\usepackage[colorinlistoftodos,prependcaption,textsize=tiny]{todonotes}
\newcommandx{\unsure}[2][1=]{\todo[linecolor=red,backgroundcolor=red!25,bordercolor=red,#1]{#2}}
\newcommandx{\change}[2][1=]{\todo[linecolor=blue,backgroundcolor=blue!25,bordercolor=blue,#1]{#2}}
\newcommandx{\info}[2][1=]{\todo[linecolor=OliveGreen,backgroundcolor=OliveGreen!25,bordercolor=OliveGreen,#1]{#2}}
\newcommandx{\improvement}[2][1=]{\todo[linecolor=Plum,backgroundcolor=Plum!25,bordercolor=Plum,#1]{#2}}
\newcommandx{\thiswillnotshow}[2][1=]{\todo[disable,#1]{#2}}

%allow the use of the \cite{NEEDED} command
\usepackage{ifthen}
\let\oldcite= \cite
\renewcommand \cite[1]{\ifthenelse{\equal{#1}{NEEDED}}{[citation~needed]}{\oldcite{#1}}}

\docbegin

\title{Recent Advances in Sandboxing}
\author{Christoph Heidrich}
\authorURL{christop.heidrich@tu-ilmenau.de}

\maketitle
% initial config
%\nocite{*}
\begin{abstract}
\{ Insert Abstract here\}
\end{abstract}

% --> Im Text sollte \section der "h�chste" Gliederungsbefehl sein,
%   Bitte _neue_ Rechtschreibung verwenden!
%   kein include, input newpage oder \\
%
%	 Auf Zeilenimbr�che alle 80 Zeichen achten
%	 Rechtschreibung pr�fen!
%   Men�: Edit -> Spell -> Select Deutsch8, dann Edit -> Spell -> Check Buffer)

%\todo{The original todo note withouth changed colours.\newline Here's another line.}
%\lipsum[11]\unsure{Is this correct?}\unsure{I'm unsure about also!}
%\lipsum[11]\change{Change this!}
%\lipsum[11]\info{This can help me in chapter seven!}
%\lipsum[11]\improvement{This really needs to be improved!\newline\newline What was I thinking?!}
%\thiswillnotshow{This is hidden since option `disable' is chosen!}
%\improvement[inline]{The following section needs to be rewritten!}
%\lipsum[11]
%\newpage
%\listoftodos[Notes]

%to get back to german notation replace all `` with '\glqq ' (including the space!!) and all '' with '\grqq{}'

\section{Introduction \& Overview}
\label{tH02_Overview_Sandbox}
%Short Overview over the topic of sandboxing: explanation of general concepts, definition of status quo. Possibly pointing out current restrictions and weaknesses, which can be referenced in the following chapters

%\todo[inline]{kernel-level vs user-level sandboxing?}
%\todo[inline]{Sandboxing-Anwendung Isolation, Restriction for protection, but also behavioural analysis. Source for the necessity of sandboxing for malware analysis in advance of detection can be quoted from t02\_AASandbox. Signature Analysis and understanding of behaviour to allow future static analysis.}

The process of ``sandboxing'', the isolation and confinement of software to a specifically defined and controlled environment in general, has become a commonly acknowledged and widespread technique in various areas of application and is not considered anything special or ground--breaking anymore. Nonetheless there has still been some research and progress over the last few years which will be covered in detail in the following sections. As ``recent advances'', as described in the title, is considered anything published over the last 5 years, that is since 2010. This work does not raise any claim to completeness but can be considered as an overview over a vast topic, singling out interesting or innovative examples.

Before we go into detail regarding the latest progressions, this paragraph will give a brief overview of the general concepts of sandboxing technologies as a defined status quo suitable for later reference. Generally speaking, sandboxes allow the execution of code in a controlled and monitored environment. The main goal of a sandbox is to prevent said program from escaping this confined environment and restrict its resource access, e.g. its access to features provided by the operation system. This also includes the isolation and protection of multiple sandboxed applications from one another. This may be used to run multiple applications on mobile devices without interference or to incorporate multiple web--applications from various unknown sources into a single website without putting users at risk. In addition to protecting the host system from unwanted access and alteration, sandboxes are also often used to analyse possibly malicious software and its behaviour to identify new, unknown malware and use the information for future malware detection \cite{t02_Hoopes}[p. 64]. A commonly followed approach to achieve this is software--based fault isolation (SFI), a combination of static code analysis and safety checks performed at runtime. Prior to execution, the sandboxed code is analysed and checked for patterns of known malicious code segments as well as generally critical operations, allowing the application to access hardware-- or operation--level functionality (e.g. executing system calls) or perform any kind of control flow transfer. These sections are injected with software guards --- short, inline instruction sequences that allow the sandbox to perform safety checks on wrapped operations or to sanitize critical parameters at runtime, effectively securing the integrity of the sandbox \cite{t02_Ansel}[p. 356]. If the sandbox is used to analyse the behaviour of malicious software and the alteration of the host system is not prevented, usually an additional mechanism like an encapsulating virtual machine is used to allow easy restoration of the system to its initial state \cite{t02_Hoopes}[p. 68f].

There are several criteria that determine the quality of a sandbox and its applicability to a certain use case. In this paper, the following criteria will be used to evaluate the results and findings of each presented paper at the end of each section:

\begin{enumerate}
     \item Execution performance of the sandboxed application;
	 \item Possibility of alteration of the host system / escaping the sandbox;
	 \item Resistance to detection;
	 \item Transparency and accuracy of the enclosed program's execution;
  \end{enumerate}
  
Monitoring a program's behaviour as well as intercepting and sanitizing performed system calls can introduce a significant overhead which may result in notably longer execution time. This is not only impractical from a user's perspective but also allows modern malware to recognize the sandboxed environment and evade detection by displaying benign behaviour \cite{t02_Cappos}[p. 6f]. Hence, it should be as low as possible. Possibilities that allow alteration of the host system or escaping the sandbox should be non--existent. In addition to those core principles, the last two criteria especially target sandboxes which are used to detect and analyse possibly yet unknown malware. To minimize the already mentioned risk of malware evading detection, detection of the sandbox environment itself should be impossible. And finally, to allow accurate analysis of the possibly malicious behaviour of the application, said behaviour should be transparent and identical to its unrestricted execution \cite{t02_Kruegel}[p. 1].



%Cites
% t02_Hoopes - Book, Virtualisation for Security
%t02_Kruegel - Paper, Full System Emulation

\section{Advances in OS--based sandboxing}
\label{tH02_OS_based}
\subsection{File--system layering on OS--level}

As presented in section \ref{tH02_Overview_Sandbox}, sandboxes offer a variety of helpful features regarding analysis and protection from malicious software. However, solutions focussing on isolating malware and protecting the host system usually completely prevent access to the hosts file system or only allow very restricted access \cite{t02_Cappos}[p. 2]. Though it might sound contradictory at first, allowing alteration of the hosts file system (albeit while still assuring its protection) can be interesting for a multitude of use cases. Implemented in their sandboxing solution MBOX, Kim and Zeldovich developed a method to realize this. Like similar sandboxes it offers protection from modification by malicious software and allows flexible control of the isolated program. In addition however, they combine these features with functionality similar to an overlay file system. An overlay file systems covers one or multiple existing file systems with an additional layer, e.g. to allow write--access to an otherwise read--only system by redirecting write--operations to the overlying layer. Likewise, MBOX intercepts relevant system calls and redirects them to a virtualized file system, instead of prohibiting or restricting access in general, while still maintaining control over the application. 
%This does not only effectively protect the host but also allows (selective) transfer of the performed changes back to the original file system.
Since the simulated file system is stored as a regular directory, it can be easily accessed and examined after the termination of the sandbox using regular Unix tools \cite{t02_TaesooKim}[p. 1].

This approach introduces a variety of new use cases apart from the common security related ones. For example, it allows users without root--privileges to use the systems regular package managers to install software a process that usually would require root privileges to access system directories. However, by installing said packages in a simulated file system provided by the sandbox where a root--like environment can be emulated, it can also be performed by regular users. Other potential scenarios make use of the possibility to checkpoint the original file system, similar to the process of creating a new branch in versioning tools like GIT, e.g. while editing system configuration files. In case of a faulty setting, which would otherwise corrupt the system, changes can simply be discarded by rolling back to the original file system while successful changes can easily be applied. It even allows a profile--based sandboxing--approach where each sandboxed application is only provided with access to necessary files \cite{t02_TaesooKim}[p. 2].

 
 MBox is implemented as an extension to \textit{strace} 4.7, a Unix system utility for tracing system calls, which was modified to take advantage of the \textit{seccomp}/\textit{BPF} (Secure Computing / Berkeley Packet Filter) mechanisms available since Linux 3.5. Running a process in \textit{seccomp} mode ultimately prohibits it from using more than a well--defined set of system calls. BFP itself is an active packet filter, which originated from network traffic monitoring and allows to scan and possibly discard packages that do not match certain filter criteria \cite{t02_McCanne}[p. 1]. In this case, it is used to examine system calls prior to their execution regarding their accordance to the limits set by \textit{seccomp}. Accordingly, the BFP application only invokes MBox on critical system calls, leading to a reduction of those observed by \textit{strace}, increasing overall performance. Critical operations, e.g. those targeting file system access, are intercepted and sanitized by MBox. Their arguments are rewritten to point to the virtual file system. If MBox is used on systems running a kernel older than 3.5 where seccomp / BFP is not available, it falls back to use solely \textit{strace}, which results in interception of all system calls performed by the application and hence a higher overhead \cite{t02_TaesooKim}[p. 4].
 
 The introduction of a separate virtual file system leads to a variety of pitfalls when implementing the sandbox, two of which should be addressed here. The first regards the commit of changes performed on files in the virtual file system. MBox effectively implements a copy-on-write policy, which means that files are only duplicated to the sandbox file system once it tries to modify them, redirecting subsequent reads to the modified copy instead of the original. After the termination of the sandbox, the original file may have been altered by another program, possibly requiring a merge of both files. MBox can detect such conflicts by storing a hash value of the original file while creating the copy and comparing it prior to the commit. However, it is unable to automatically solve them and they have to be addressed manually by the user \cite{t02_TaesooKim}[p. 3]. The second issue regards the common TOCTOU--problem time--of--check--time--of--use), describing the approach of overwriting the memory addressed by arguments that have essentially been checked, sanitized and proven to be benign with harmful operations from another thread. MBox avoids this problem by making use of the possibility to write any sanitized argument or data structure to read--only memory page using \textit{ptrace} and changing the affected system calls pointer to this copy. If the system call enabling alteration of said memory page is invoked by a sandboxed process, it is automatically killed by the sandbox, effectively preventing any attacker from exploiting TOCTOU--issues. \cite{t02_TaesooKim}[p. 4]
 
 The performance overhead introduced by MBox is highly dependent on the nature of the sandboxed application. Whereas applications running mostly in user space (tested with Octave Benchmark) introduced only a minor overhead of 0.1\%, applications heavily relying on system calls, e.g. for file access (tested with Zip and Untar operations), lead to a more significant overhead of 12 -- 21.9\% \cite{t02_TaesooKim}[p. 4]. The possibility of alteration of the host system and escape from the sandbox needs closer examination since the purpose of the presented solution is to \textit{allow} alteration of an overlay file system within certain boundaries. Yet, the presented implementation should assure that all critical system accesses are intercepted and sanitized. Kim and Zeldovich however did not perform any subsequent evaluation of this claim. It should be noted that storing the virtualized file system as a conventional folder structure may pose a viable security risk, enabling an attacker to introduce malicious files to the hosts system, which may be accessed or executed after the sandbox is terminated. Transparency and accuracy of the enclosed program's execution should not be affected, since the application is not restricted in its execution. For the same reason, risk of detection for the sandboxing environment should be rather low, though the relevance of these two characteristics is quite disputable, since in comparison to different solutions, sophisticated malware analysis is not the key use case of the presented solution.


\subsection{Secure sandboxing despite bugs in memory--safe code}
%Extracting the standard libraries from one single trusted code based and isolating them from one another separated from the rest of the sandbox hinders exploitation of flaws present in those libraries and provides better isolation.
%t02_Cappos

It is in the general purpose of sandboxes --- isolating possibly malicious software --- that they play a crucial role for security in many of today's digital applications. Consequently, flaws in the construction of a sandbox that allow the isolated application to escape, pose a vital risk to security. However, due to the general architecture of modern sandboxes, being completely bug--free is hard to guarantee. In general, sandboxes consist of three different components: the sandboxed untrusted application code, the interpreter for the core language the sandbox is written in and a large amount of standard libraries, which provide the general functionality. Parts of the latter are used to perform the critical operations that the sandbox restricts and mediates between the isolated application and the operating system and represent the trusted code base (TCB) of the sandbox. Accordingly, parts of those libraries contain operations written in native code to access system resources. In accordance to security--related best--practices however, large parts of these libraries are written in memory--safe languages to increase security \cite{t02_Cappos}[p. 1]. A programming languages can be classified as being memory safe when it avoids vulnerabilities based on the exploitation of bugs in system memory access, e.g. through the exploitation of dangling pointers, buffer overflows or type casting. Languages like JavaScript are classified as memory--safe, C or C++ are not \cite{t02_Szekeres}.  However, according to \cite{t02_Dean}, even bugs in memory--safe code present a significant risk and possibly allow an attacker to escape the sandbox.

This shall be briefly illustrated at the example of the Java Sandbox, which executes applications of a technically secure memory--safe language. Java applications are not allowed to call native code directly, which is enforced by different components of the sandbox. Instead, this functionality is implemented as part of the standard libraries. The sensitive functions are classified as private and cannot be accessed directly as well, but instead are called through public wrapper functions that mediate and verify access and enforce a security policy. Nonetheless, these sensitive functions do pose a major security risk. Since Java libraries are organized as packages, objects may contain both privileged and unprivileged code as well as data members extending the scope to other files, effectively interlinking many packages. Java's native method calls scatter around 500 different classes contained in various libraries. However, only 350 of these restrict the scope of the sensitive methods by classifying them as private, leaving many of them vulnerable to abuse. This ultimately shows that if any part of the large trusted code base is flawed (due to faulty wrappers or an unintentionally large scope), untrusted code may directly access sensitive native functions and hence undermine overall security \cite{t02_Cappos}[p. 2f].

To address this problem, Cappos et al. developed a sandbox technique that moderates the impact of a security failure in a standard library, implemented in a custom language subset of Python. They archived this by splitting the traditional monolithic TCB into multiple parts and moving as much functionality as possible out of the kernel into separate libraries. The sandbox itself is organised as a stack of isolated ``security layers'', each with a set of security--verified capabilities that allows controlled interaction, as depicted in Fig. \ref{memory_layer}. Each layer is instantiated by the one beneath it, passing along at most a subset of its own capabilities, with the kernel at the bottom of the stack. Since it keeps control over all its descendants, only a vulnerability in the kernel itself can compromise the sandbox in its entirety, a flaw in a layer may only affects its children.

\begin{figure}[htb] 
\centerline{\includegraphics*[width=0.5\textwidth]{img/Memory_Layer_Arch.png}}
\begin{center}
\caption{Architecture of the sandbox with stacked security layers \protect \cite{t02_Cappos}}
\end{center}
\label{tH02_img_safe_load_arch}
\end{figure}

This security layer design is implemented based on two mechanisms. First of all, two calls to a \textit{virtual namespace} provided by the customized kernel allow the validation and execution of dynamically added code at runtime to load the split--up libraries. The mandatory capability mapping provided with the execution of the executing call ensures that the namespace does not contain any capability that was not explicitly granted. However, this does not enforce isolation between the libraries. This is ensured by the \textit{encasement library}, which implements the layer abstraction between the libraries and is located right above the kernel in the architecture. To avoid shared objects or functions between the layers, only copies created by the encasement library are passed between them. So called \textit{contracts} detail the capabilities of each layer and are used to filter and verify function calls that can be used by other layers, which are itself wrapped inside a verification function by the encasement library. If a violation is detected, the sandboxed program is terminated \cite{t02_Cappos}[p. 4].

To provide functionality similar to other sandboxes and still maintain the benefits from isolation, the kernel implements various capabilities spanning network functions, I/O calls, locking mechanisms as well as thread-- and encryption--related calls that are provided to the untrusted layers building upon it. Using these, the authors built standard libraries providing common language functionality for their Python derivative while following the isolation paradigm \cite{t02_Cappos}[p. 5].

To evaluate the benefit of isolating the libraries and excluding them from the trusted code base, Cappos et al. analysed the impact of 30 known bugs of the Java Virtual Machine and compared how they would affect program execution, if the flawed components were translated and isolated in their sandbox as isolated libraries. Since this evaluation is only of qualitative nature and highly subjective, each bug and its impact was also independently categorized by three additional authors. It was found that a minimum of 75\% of the applicable bugs that lead to the execution of arbitrary code in the JVM could have been prevented. As with other sandbox implementations, impact on performance is considered as an additional factor for evaluation. Initializing of the sandbox (135 ms), security layers ($\sim$ 3 ms each) as well as the encapsulating encasement library (38 ms) add to the execution time. However, regarding these marginal values, they were found to be acceptable if not negligible. Despite execution time each security layer also adds a memory overhead needed for the contracts, wrappers as well as the duplication of passed arguments. On a system with a 64--bit memory address each layer consumed an additional 19kb of memory, which should be more than acceptable --- even for the most limited and lightweight devices \cite{t02_Cappos}[p. 6f]. Nonetheless, though marking an interesting an promising approach, these results should be taken with a grain of salt, since the conducted evaluation is still quite questionable despite best efforts. Unfortunately, Cappos et al. did not perform any evaluation regarding detectability and transparency of their solution, which is why these criteria are omitted in this valuation. Nonetheless, if future work confirms this approach, the security of sandboxing could vastly improve. 


\subsection{Safe Loading}
\label{safe_loading}
%Replacing the standard application loader with a more security--focussed one and linking it with the sandbox to allow better fault isolation. This way, information about the application behaviour can be passed to the sandbox in advance of program execution.

Modern applications are no isolated constructs only relying on their own resources, but make use of many shared objects like additional libraries loaded at runtime. Because of this, one of the key components of many systems is the dynamic loader. It resolves these dependencies, replaces references in the applications code accordingly, and loads the application as well as required shared objects into memory before the application is started. These loaders usually are optimized for fast resolving and loading of said dependencies and often offer additional functionality for debugging or tracing purposes. However, this richness in functionality and the fact that all application, regardless of their scope or possible security aspects, make use of the same loader classifies them as a prominent target for attacks. The fact that it has to deal with additional problems when used in a security related context (like a sandbox) only worsens the case even more. When loading a privileged program, the aforementioned additional features prove to be rather obstructive or even harmful, since they could be abused to preload alternative, possible harmful libraries. Effectively, the loader should ensure that these functions are not available, especially when an application is started with higher privileges (e.g. by using the SUID / 'Set owner User ID' flag, which enables a user to execute a file with the owners permission instead of his own \cite{t02_Kumar}) Nonetheless, there are multiple reported cases where faulty or missing checks lead to privilege escalation, which were abused to execute injected or construct malicious code with the provided higher privileges. Additionally, when used in combination with a sandbox that uses the loaders LD\_PRELOAD option to inject libraries into the application to gain control over it, the dynamic loader treats the sandboxes injected binary translator similar to any other loaded object, 
%\todo[inline]{explain what a binary translator is and does in chapter 2!. Sources on Page 21}
which enables the sandboxed application to access information about it. Another critical point is, that it is not guaranteed that the initialisation function of the binary translator (which effectively takes and ensures control over the application) is the first instruction to be executed by the loader. If any other library sets an ``INITFIRST'' flag, the injected library is \textit{loaded} prioritized, yet the loader \textit{executes} the last library that was loaded with this flag set, which possibly enables the application to circumvent the sandbox. And finally, many existing sandbox implementations either do not support dynamic loading or treat the loader as a black box residing next to the sandboxed application (see \cite{t02_Scott} and \cite{t02_Yee} for reference), allowing it to load and map new code into the running process \cite{t02_Payer}[p. 21f]. Albeit probably sanitized and controlled by the sandbox through injected code guards, this unnecessarily increases the encapsulated applications capabilities.

\begin{figure}[htb] 
\centerline{\includegraphics*[width=0.4\textwidth]{img/safeLoading.png}}
\begin{center}
\caption{Comparison between a regular sandboxing approach and the safe loading architecture provided by TRuE \protect \cite{t02_Payer}}
\end{center}
\label{tH02_img_safe_load_arch}
\end{figure}

Payer et al. try to address these problems by introducing a trusted runtime environment (TRuE), that combines a customized ``safe'' loader and a sandbox within the same domain to provide a protected foundation for application execution. In contrast to a conventional sandbox, where the standard loader itself, the application and all required libraries are placed within the sandbox, TRuE positions the first two in a shared privileged domain while the untrusted application code as well as all additionally required libraries reside in a lower--privileged and controlled application domain. This allows a tighter coupling of the loader and the sandbox and enables them to share information about the sandboxed program (see Fig. \ref{tH02_img_safe_load_arch} for comparison). The resource addresses resolved by the loader during application initialization can be embedded directly into the code translated and sanitized by the sandbox resulting in all control transfers during execution being direct references of the respective libraries, unreadable and unalterable by the application. Since the loader is aware of the status of the sandbox, this also resolves the problem of packages being load prior to the initialization of the sandbox as discussed earlier in this chapter \cite{t02_Payer}[p. 23]. Furthermore, since the loader and the application no longer reside in the same domain, the application is no longer able to map additional executable code into memory directly. Instead, the safe loader is the only component allowed to load additional code. It is still accessible from the application domain, however only through a well--defined API tightly controlled by the sandbox \cite{t02_Payer}[p. 22]. 

The sandbox domain itself acts similar to many known sandbox implementations. The untrusted application code as well as all external resources are inspected prior to execution and injected with security guards to ensure sandbox containment. System calls are intercepted and sanitized prior to execution and due to the tight coupling, unresolved targets for control flow transfers can be loaded and verified dynamically. Indirect control flow transfers are checked before they are carried out to ensure only verified and sandboxed resources are reached.
The design of the secure loader itself helps avoiding the problems related to weaknesses in regular application loaders presented beforehand. Placing the loader within the sandbox domain, separated from the application already efficiently prevents it from accessing and possibly exploiting its internals and functionality while providing the loader with the necessary privileges to resolve dependencies. To prevent privilege escalation attacks when dealing with applications using the SUID flag, the secure loader only implements a subset of the native functionality. The set is complete enough to allow resolution and loading of required resources but skips any functionality targeting debugging, execution of user provided code, backwards compatibility or direct access to the loaders internal data structure from the application. In addition, settings of the secure loader are all hard--coded. The configuration files can only be changed prior to compilation, alteration through the user at runtime is not allowed. When the execution of the application is initiated by the user, the initialisation of the secure loader is the first command that is run. Since this initializes and starts the sandbox, any disruption by the application is prohibited and it is started directly under the control of the sandbox \cite{t02_Payer}[p. 23].

Again, the solution is evaluated using the criteria presented in chapter \ref{tH02_Overview_Sandbox}. Performance tests were conducted with multiple synthetic benchmarks as well as real world applications. While in most benchmarks using TRuE resulted in a reasonable overhead of almost 0\% to 8\%, tests that incurred a high number of indirect control flow transfers --- triggering a runtime check by the sandbox --- introduced a very noticeable overhead of up to 85\% in runtime. The average incurred overhead combined over all performed benchmarks was a mere 15\%, which should be acceptable for most use cases.

However, authors performed an additional test using a real world application (Open Office 3.2.1), which makes heavy use of shared resources. When compared to the unprotected start--up using the standard loader, a sever overhead of 188\% was introduced when applying the protective sandbox and the secure loader due to the high number of references that need resolving. Without the sandbox, the secure loader itself including memory protection still imposed an overhead of 77\%. Even though this was meant to reflect a worst case scenario, it still represents a probable use case and depicts how gravely performance might be impacted \cite{t02_Payer}[p. 29]. Regarding the detectability of the sandbox environment as well as transparency of the the application's execution, no specific tests were conducted, since the solution is not specifically targeted towards malware analysis. Yet, the possible increase in execution time may allow detection of the restricting environment.
%geht das auch besser?...

From a security point of view, TRuE introduces a safe foundation for the execution of untrusted applications that overcomes many of the problems of the standard application loader and introduces various benefits through the combination of a sandbox and a secure loader compared to independent usage. However, the applied approach limits the solution in its flexibility. Since the application domain is not allowed to introduce additional code on its on as it cannot be differentiated from malicious injected code, applications that make use of just--in--time compilation are not supported. This could be addressed in future work by introducing a JIT compiler to the sandbox domain or extending the Sandbox API to allow checks of introduced code. An additional point of criticism also regarding flexibility is that stripping down the functionality set provided by the loader may make the solution unsuitable for an unknown number of use cases relying on these capabilities. Since the authors declared goal was to provide a solution with a ``rigorous security concept'' \cite{t02_Payer}[p. 18], criticism of such kind may not be appropriate.

\section{Advances in web--based sandboxing}
\label{tH02_Web_based}
\subsection{Software--based fault isolation for dynamic runtime--environments}
\label{tH02_dynamic_web_sandbox}
%One of the initially provided papers. Introducing a method allowing effective software--based fault isolation and static code checks despite highly dynamic environments including just--in--time compilation and runtime code editing.

Regarding the growth in cloud computing, applications and services provided on the Internet play an ever--increasing role. Websites often incorporate dynamic, untrusted content from various sources besides the purposeful code provided by the accessed site to augment their appearance and service. These external scripts run with the same privileges than the intended first--party code, making the website a worthwhile target for attacks. The encapsulating runtime environment --- web browsers --- often allow customization and extensibility through plug--ins and hence offer various opportunities for exploitations. All of this makes sandboxing an essential necessity in this context, encapsulating and isolating applications and widgets from each other as well as mediating access to the resources provided by the browser \cite{t02_ADsafety}[p. 1]. The provided web applications are often written in dynamic languages like JavaScript, executed on complex language runtime platforms like the V8 JavaScript engine, that provide additional security features for isolation as well as additional functionality for runtime code modification and just--in--time compilation to increase efficiency. These platforms however often rely on large amounts of native code libraries, which pose a major security risk due to possible flaws in their implementation. Thus, each such runtime platform, implementing its own security measures, poses as an additional target for attacks, as evidently demonstrated by periodic reports about new successful exploits of web--based applications and known vulnerabilities \cite{t02_CVEDetails}.
%t02_Ansel

Ansel and Marchenko aim to address this problem by presenting an extension for the Native Client open--source project, which allows them to safely and efficiently sandbox entire dynamic language runtimes, including their native code base while still supporting features like runtime code modification and just--in--time compilation. While the unmodified Native Client (NaCl) provides sandboxing functionality and allows program execution independent from the underlying operating system, it requires pre--compiled applications, effectively preventing modification and extension of the code at runtime \cite{t02_GoogleNaCl}. By encapsulating the entire dynamic execution environment, their solution allows independent sandboxing regardless of the language used for implementing the application and does not limit implementation options. The following sections will give a brief overview over the technology before detailing the design of the extension.

The Native Client is an open--source sandbox implementation for x86 and ARM architectures. It uses software--based fault isolation to restrict the execution of unsafe code by combining static code analysis and dynamic surveillance of its execution using runtime safety checks. Both methods are performed on pre--compiled machine code. The static analysis verifies that the code complies to given criteria and constrains its execution where necessary. Injected software guards allow surveillance of the code during its execution and may be used to sanitize critical operations and passed parameters, e.g. verifying memory addresses while performing system calls to point to sandbox controlled memory regions. The sandboxed machine code is organized and encapsulated in in instruction bundles, each comprising a single possibly unsafe instruction combined with a software guard. Multiple instruction bundles are combined to a code region, each of which is independently verified for safety by the native client \cite{t02_Ansel}[356f].
The presented NaCl--extension allows the application of these SFI techniques to code generated and modified at runtime, e.g. when using a runtime platform which makes use of just--in--time compilation. To do so, three interfaces were added to the NaCl implementation to allow dynamic addition, modification and deletion of such code regions. Their design will be briefly discussed in the following section.

To add a new code region to the sandboxed application, the JIT compiler --- which already resides within the sandbox as a part of the runtime platform --- generates the new machine code and calls the respective interface, transferring control to the sandbox. It encapsulated each instruction and aligns it to its boundaries. Multiple of these instruction bundles are combined to a single code region, which are independently verified that control flow transfers between them solely target the start of instruction bundles to avoid circumvention of the encapsulation. To prevent code execution before a complete code region has been copied to executable memory, the first byte of each contained instruction bundle is written as a HLT (``halt'') instruction as long as copying is in progress, resulting in immediate termination of all threads of the native client when executed. Their intended value is written as the final step of the copying progress. The interface for safe modification of existing code regions at runtime is implemented in a similar way, though in addition atomicity of the modification progress has to be ensured. Any NaCl thread should only be able to execute either the old or new set of instructions. This is achieved by using the regular atomic write operation provided by the systems processor. However, this operation is limited to 8 byte memory regions on some processors. To allow conflict--free modification of larger regions, memory synchronisation barriers are used, ensuring the integrity of the modification process. Since the size of the memory space addressable by the Native Client is set at link time, deletion of dynamically generated code regions is also supported to reclaim the executable memory once specific regions are no longer needed. To assure the safety of the process and maintaining the integrity of the sandbox some factors have to be taken into account: First, it has to be ensured that the code region has been created dynamically to avoid alteration of the platform itself. Secondly no thread currently should be executing the to--be--deleted code region or have its instruction--pointer point at the respective memory address. The latter is ensured by marking the relevant code region for deletion but prohibiting its reuse until each thread has invoked the Native Clients trusted runtime, effectively ensuring that no thread is in the critical code section \cite{t02_Ansel}[358 -- 360].

Ansel and Marchenko likewise tested their implementation with regards to performance and introduced overhead. Before their findings are discussed in more detail however, one particular shortcoming of their solution shall be addressed. The targeted language independence of their solution comes with the burden of adapting the runtime platform --- more specifically the JIT compiler --- to emit code that can be safely sandboxed within the Native Client and matches its code safety verification. This adds additional effort for each supported language. Since compilers usually differ between architectures, porting them becomes even more complex. The following performance results were measured on the 32-- and 64--bit implementations of the V8 JavaScript engine and Mono Common Language Runtime, manually ported by the authors to operate within the Native Client (no specific versions mentioned). To simplify code portability, NaCl utilizes the ILP32 data model for both, its 64--bit as well as the 32-bit implementation. Since the 64--bit versions of both ported runtimes naturally expect the use of a corresponding 64--bit data model, their ported implementations were modified accordingly. These changes had a sensible impact on the performance of the runtime, resulting in noticeable worse benchmark results compared to the 32--bit versions. JavaScript performance was measured using the V8 JavaScript Benchmark Suite as well as the Sunspider Benchmark, resulting in an average overhead of 30\% (32--bit) respectively 55,5\% (64--bit). For Mono, performance was tested using the SciMark C\# benchmark suite, resulting in an overhead of only 2\% for 32--bit and 21\% for 64--bit.

\begin{figure}[htb] 
\centerline{\includegraphics*[width=0.6\textwidth]{img/JIT_vs_AOT.PNG}}
\begin{center}
\caption{Absolute performance of SciMark C/C\# Benchmark Suite, native execution, pre--compiled (AOT) and JIT as well as sandbox slowdown in parentheses. \protect \cite{t02_Ansel}}
\end{center}
\label{tH02_AOT_vs_JIT}
\end{figure}

However, the innovative benefit of the presented extension is to allow sandboxing of JIT--compiled code. To evaluate the relative cost of sandboxing pre--compiled native code versus JIT--compiled code, Ansel and Marchenko compared the performance of three variations of the SciMark benchmark: as a native C implementation, as a C\# port compiled ahead of time and the and lastly as the same port executed using JIT compilation, both running on the Mono CLI and implemented as a 32--bit and 64--bit variant. Executed without the sandbox, the JIT compiled version of the port is faster than its pre--compiled counterpart since it can optimize the code as it is generated. Remarkably, this still holds true when executed within the native client. However, both executions were notably slower than the native run without a language framework. These results suggest, that the overhead introduced by language--independent sandboxing may be negligible compared to the slowdown induced by the dynamic language runtime itself (see Fig. \ref{tH02_AOT_vs_JIT}).\cite{t02_Ansel}[p. 362ff] Since the porting of both runtime environments does not result in significant changes regarding the application's behaviour, accuracy of the programs execution should not be affected. As with previous solutions, the increase in execution time may result in an increasing probability of detection of the restricting environment.

Language--independent software--based fault isolation, achieved through successfully sandboxing entire runtime environments makes it possible to safely run programs using self--modifying code with a noticeable but reasonable overhead. Since the presented extension does not rely on characteristics specific to the utilized Native Client, the general idea is very likely to be applicable to other sandboxing solutions as well. Despite the obvious benefits of securely sandboxing applications that make use of self--modifying code, the solution may also be beneficial for application and language deployment on the web in general. By enabling an entire language runtime to be isolated within a sandbox, this gravely facilitates the adoption and applications of new languages on the web. Such language may offer a richer, specifically needed functionality but weaker security due to its immaturity --- which can now easily be suspended by running it in a safe environment. Nonetheless, the additional expenditure of aligning the runtime environment to run within the sandbox or porting existing ones is a drawback that definitely has to be accounted for. It should be noted that since the publication of the presented paper, Google released PNaCl, a slightly altered version of the Native Client. It avoids the problem of providing multiple executables for different architectures by providing applications as an unspecific bitcode executable called \textit{pexe}, which can be translated to an architecture--specific one within the Chrome browser. This approach still does not provide applications with easy mechanisms for runtime code modification or similar functionality, but may be a worthwhile topic to conduct further research on. \cite{t02_GoogleNaCl}

% talk about PNaCl somehow?

%Conlcusion:
%- general idea can be applied to different sandboxes other than NaCl since their work is not based on specific NaCl characteristics but fundamental characteristics fulfilled by many other
%- combination of SFI and JIT / dynamic code generation is possible, though there is a performance impact.
%- new use case for language independent sandboxing: facilitate the deployment of new languages on the web (possibly weaker security but richer, specific feature set) by sandboxing it with its entire runtime.
%- however comes with the disadvantage of enabling the runtime to emit sandboxable code.


\subsection{Type--based verification of Web--sandbox security}
As it was already depicted in chapter \ref{tH02_dynamic_web_sandbox}, sandboxing plays an important role for the security of modern websites. But despite the presented possibility to enable JIT compilation and support arbitrary runtime environments, applications and widgets on the web face sandboxes with another, more fundamental challenge: JavaScript, which is often utilized for web applications, imposes high requirements on sandboxes due to its rich feature set and specific characteristics. Dynamic typecasting, the context--sensitive scope of variables and references as well as the lack of private fields and the possibility to easily modify and extend objects at runtime using \textit{prototype} lead to a multitude of problems that sandboxes for web--applications must address. They make it near--impossible to verify applications using static checks but demand for more and more sophisticated methods of dynamic analysis. This results in more advanced and complex sandbox implementations, that likewise become harder to review. An independent team reviewed the Caja sandbox to evaluate its quality and stated that ``[it is] hard to review [...] which hurts maintainability and security''\cite{t02_Caja}[p. 2]. It was also found neither specification nor documentation of the implementation were sufficient. Both these points of criticism outline a critical problem: the safety claimed by a sandbox solution becomes more and more difficult to verify with increasing complexity. In addition, this also makes it harder for users to determine whether a solution is implemented correctly and fits their aspired goal and use case\cite{t02_ADsafety}[p. 3]. 

Politz et al. try to address this problem and developed a strongly automated method for the verification of sandbox safety, based on a novel type system that evaluates the sandboxes properties. They applied their system to the ADsafe Sandbox and used the resulting type model to evaluate its implementation. Before presenting their solution in more detail, aforementioned properties that were used to define a secure sandbox in the context of their work shall be briefly presented. According to \cite{t02_ADsafety}, they list as follows:

\begin{itshape}
If the containing page does not augment built--in prototypes, and all embedded widgets pass JSLint, then:
\begin{enumerate}
     \item widgets cannot load new code at runtime, or cause ADsafe to load new code on their behalf;
	 \item widgets cannot affect the DOM outside of their designated subtree;
	 \item widgets cannot obtain direct references to DOM nodes; and
	 \item multiple widgets on the same page cannot communicate.      
  \end{enumerate}
\end {itshape}



The developed type system models the behaviour and restrictions of the components that the sandbox interacts with: the sandboxed application itself as well as the web browser as the sandbox runtime including the programming language. Their type--based representation will be discussed in the following section.

\begin{figure}[htb] 
\centerline{\includegraphics*[width=0.5\textwidth]{img/widget_type.PNG}}
\begin{center}
\caption{The \protect \textit{Widget} type. \protect \cite{t02_ADsafety}}
\end{center}
\label{tH02_widget_type}
\end{figure}

Their is no specification of the structure of an application that may be encapsulated in a sandbox. However, every sandbox expects to execute against application that passed its static code checks. In the case of ADsafe, static checks are performed using JSLint. Politz et al. therefore specified a type \textit{Widget} that reflects said checks. It regards any type and shape of value or expression that is used by the application and may be passed to the sandbox. Corresponding to the check performed by JSLint, it restricts or blacklists certain expressions. The entire specification for the type Widget is displayed in figure \ref{tH02_widget_type}. In addition, the safe interaction of the sandbox with its own runtime environment as well as the handling of the many peculiarities of JavaScript need to be taken into account. The browser environment and all its provided methods for DOM access are represented similar to the widget type, either being forbidden (e.g. \textit{eval} and similar functions) or restricted (e.g. \textit{timeout}, which must not be called with strings as arguments or it behaves similar to \textit{eval})\cite{t02_ADsafety}[p. 4ff]. To avoid problems with any idiosyncrasies in the implementation of the sandbox during analysis, the authors furthermore used mechanisms provided by \cite{t02_Guha}, which transform regular JavaScipt applications to a subset of the JavaScript language called $\lambda _{JS}$. $\lambda_{JS}$ programs behave equivalent to the original application, but implements them only by using the languages core semantics, which makes them easier and foremost consistent to analyse.

The presented type model with the \textit{Widget} type at its core was then used to verify the behaviour of the adsafe.js runtime library which resulted in Politz et al. to discover several new bugs in ADsafe. However, there are some drawbacks of their solution that need mentioning. It was impossible to apply their verification approach to ADsafe without any refactoring of the runtime libraries, since they implemented programming patterns they were not able to verify with their type system\cite{t02_ADsafety}[p. 9]. Since the type system is intended to be universally applicable to any JS--based sandbox solution, this would not only require the implementation of new types similar to \textit{Widget} to represent checked applications for the sandbox, but further increase the required effort to refactor these constructs.

Nonetheless, the verification of a sandbox on a type--based approach in general yields a few benefit.First of all most developers are familiar with type systems, ensuring understanding of what the system says about their code, e.g. when not all properties are met. Secondly, verification based on predefined types is generally faster than evaluating a system via whole--program analysis. And finally, Politz et al. proof the soundness of their type system as part of their work, making it an effective tool for verification \cite{t02_ADsafety}[p. 4]. However, the main benefit of their solution may not even lie in the verification of existing systems, but supporting and simplifying the development of new ones. By formally specifying the properties of the sandboxed application as well as the systems environment, developers can use the presented type system to design their systems with its safety and integrity in mind right from the beginning \cite{t02_ADsafety}[p. 13]. The approach benefits a tight development cycle since tests are automated and can be easily repeated in short intervals. 



%benefits:
%automated testing, especially handy for frequently repeated testing e.g. when develloping an new sandbox, which is possible due to the short ``runtime'' DONE
%automation is less error prone and lesse expensive than review by a human 



%One of the initially provided papers. Introducing a method for a simplified functionality \& security verification of currently in development or new sandbox systems, based on codified qualities.


\subsection{Real--time analysis of websites}
Despite actually sandboxing possibly dangerous content on the web, there are infrastructure--based approaches to counter the spread of malware through infected websites. Systems like McAffee SiteAdvisor \cite{t02_McAffee} or Microsoft's SmartScreen \cite{t02_Microsoft} continuously analyse websites and classify them based on specialised heuristics. If a user accesses a website, an associated plug--in queries the systems database prior to navigation and redirects the user to a warning page, if the site is classified as malicious. Though this approach has its benefits, it suffers from some major disadvantages: first of all, upon every site access, the browser has to request the relevant information from a remote database, causing overhead and dependence on a remote architecture. Secondly, since the systems analytic crawlers often only access a site once during the analysis, the chance for false negatives is quite high, if exploits do not execute on every visit. And finally and most important, the interval between two subsequent visits of the same site is very long, leading to inconsistencies in the database's information. But even daily visits (an impossible task regarding the amount of available websites) would leave a 24--hour time--frame for an attacker to infect a website which is listed as safe.

Dewald et al. circumvent these issues and present a transparent solution that allows client--side real--time analysis of websites and allows detection of a wide range of exploits. At its core, they utilize Mozilla's Spider Monkey JavaScript Engine to execute scripts retrieved from websites and extended it with a novel analysis framework which logs executed actions. Similar to most sandboxes, it implements methods for both static and dynamic analysis. Static analysis performs common JavaScript code checks as well as an iFrame / same--origin analysis. The former implements several heuristics for detecting manipulation of an object's prototype or maleficent use of \textit{eval} or similar functions. However, Dewald et al. discovered that many benign websites also use this functions, which is why this method is complemented by the dynamic analysis depicted later in this section \cite{t02_Dewald}[p. 5]. The second static analysis inspects whether the web page contains suspicious iFrames that may be used by an attacker to compromise a website and load content from another source. An iFrame is considered suspicious when it is hidden, e.g. through size attributes equal to zero or a position outside of the visible area, and refers to a foreign domain \cite{t02_Dewald}[p. 3].


Since many malign scripts use various, often nested obfuscation techniques to avoid detection through static analysis, the authors also integrated a method for dynamic code analysis. After the suspicious code has been extracted, it is encapsulated in a JavaScriptExecution object, which is then run in an SpiderMonkey instance. SpiderMonkey itself has been modified to recognize access to any JS object and log the performed operation. After execution has finished, the resulting log is searched for patterns that match typical behaviour of malicious software, e.g. saving code to a file and executing it using the ``run'' command. An illustration of such a log is depicted in Fig. \ref{tH02_sample_log}. These patterns currently allow the detection of seven attacks including cookie stealing, file downloads and heap--spraying--attacks among others \cite{t02_Dewald}[p. 3].

\begin{figure}[htb] 
\lstset{ 
  basicstyle=\footnotesize,
  xleftmargin=.3\textwidth, xrightmargin=.2\textwidth
}
\begin{lstlisting}[language=Java]
ADD global.mystring
SET global.mystring TO ``sometext''
GET global.alert
GET global.mystring
CONVERT alert TO A FUNCTION
FUNCTIONCALL alert (``sometext'')
\end{lstlisting}
%\caption{Log for the program \protect\lstinline{var mystring = \protect``sometext \protect''; alert(mystring);}. \protect\cite{t02_Dewald}}
\caption{Log for the program \protect\lstinline{var mystring = ''sometext''; alert(mystring);}. \protect\cite{t02_Dewald}}
\label{tH02_sample_log}
\end{figure}

Dewald et al. performed evaluation of the presented work, but their results are quite ambiguous. They tested the effectiveness of their system in terms of false positives by checking the entry page of the top 1000 websites from Alexa.com and received zero suspicions. They concluded a false positive rate of 0\%. \todo[inline]{extend this}. False negative tests were performed on 140 potentially malicious websites which were selected through the use of honeypots as well as code extracted from malware construction kits. 78\% of these samples were flagged as malicious. Of the remaining 62, multiple redirected to broke sites that possibly used to host an exploit, others did not contain an exploit at all. However, five samples performed a check on active browser plug--ins before executing the exploit and were able to avoid detection, since browser behaviour cannot yet be emulated. Another four samples used the DOM--tree structure to obfuscate the script, a method that could not be detected. During analysis of additional 10 samples, errors in the script caused it to fail, leading to an overall false negative rate of 6.43 or 13.57\%, depending on whether the ones causing the process to crash are considered possibly malicious. As an additional criteria, introduced overhead for the analysis is considered. To avoid possible distortions, only time relevant to the analysis, not for downloading the source, is considered. The checks introduced an average additional processing time of 2.112 seconds with a standard deviation of 4.292 seconds. Regarding the cumulative distribution, 90\% of all analysed pages took less than 5.1 seconds. It should be noted however, that the maximum processing time for a site heavily relying on JavaScript exceeded 60 seconds \cite{t02_Dewald}[p. 4f].

Taking into account that these results were achieved on a prototypic, unoptimized implementation, they do sound promising. Still, without further optimization, acceptance of the solution is highly questionable, since delays of several seconds will not be accepted by users and are bound to increase, since modern websites increasingly rely on JavaScript\todo[inline]{source needed!} Possible future extensions integrating analysis methods for advanced obfuscation methods may improve the already acceptable results. The pattern based approach enables easy extensibility towards the detection of future exploits while the encapsulation of the system in a single Dynamic Link Library allows simple development of extensions for different browsers. Nonetheless, there are still open issues regarding the detection of the analysis and possible countermeasures like stalling or crashing the analysis process. Unfortunately, no subsequent work has been published to date.

%conclusion:
%Benefit:
%- implementation in a single DLL simplifies development of similar extensions for other browsers than IE
%- easy to extend by implementing additional patterns to identify new malware
%- client side implementation scales without problems

%ToDo:
%- optimized 

%Critic:
%- javaScript is on the rise, amount of javascript into websites increases.
%- what happens with exploits that only trigger after xx seconds? Stalls analysis?
 

%Components:
%- core: Mozilla Spider Monkey Java Script Engine to execute scripts + analysis framework which logs every action, which is afterwards analysed for malicious behaviour, both implemented in a single DLL
%- implemented as a Dynamic Link Library which is either called from a Browser Helper Object (BHO) for internet explorer upon site access or from a wrapper executable, which allows analysis of multiple websites with a more detailed report.



\section{Sandboxes in mobile environments}
\label{tH02_Mobile}
\subsection{Relevance of sandboxing for mobile applications}
The majority of current solution for sandboxing, especially for the purpose of dynamic malware analysis, are available for commodity desktop or server operating systems due to their longer availability and omnipresent application \cite{NEEDED}. With the rise of smartphones and other mobile devices and other mobile devices over last decade however, mobile operating systems like Google's Android and Apple's iOS have become widely adopted. Due to their high popularity, people all over the world use them for a wide variety of tasks, ranging from cellular and web--based communication to security--critic actions like online banking. This, combined with the fact that many applications store personal and sensitive data locally on these phones and that it is possible to bill their owner, e.g. by calling premium numbers makes these devices prone to attacks by malicious software. Estimated numbers of 718 000 harmful applications as of 2013 \cite{t02_TrendLabs} suggest that especially on the open--source android platform, which allows software to be installed from various sources, an effective mechanism to identify malicious software is key. Regarding the ever--growing amount of mobile applications the need for an effective, automated malware analysis tool to provide the necessary behavioural footprint and classification for mobile malware--detection becomes evident. However, due to differences between conventional and mobile operating systems, limitation of device capabilities as well as the generally different structure of mobile applications as well as malicious exploits, many tried and tested solutions are not applicable. For example, even an application accessing the telecommunication functions  provided by the mobile device may exploit them by calling a premium number, generating value for an attacker.\cite{NEEDED}. Luckily over the last few years sandboxing solutions tailored to the needs of the mobile environment have emerged. The following chapters will present some, implementing innovative functionality or novel approaches, in more detail.

\subsection{Static and dynamic analysis of Android applications on Java-- and kernel--level}
As already depicted in chapter \ref{tH02_Mobile}, the mobile operating system Android is a prevalent target for attacks, partially due to the openness of the platform and the fact that users can install arbitrary software form a multitude of sources that may or may not be trustworthy. But even applications from a reliable source like Google's own official app store, the Play Store, where every submitted app is automatically checked by \textit{Bouncer}, an automated dynamic analysis sandbox, may incorporate malicious behaviour, since the detection rate and overall effectiveness of the deployed system is rather low.\cite{t02_EnterSandbox}[p. 1]. 

Echtler et al. attempt to solve these problems and introduce a system that is specifically tailored towards the needs and peculiarities of Android. Android applications are written in Java and provided to the user in form of android package file (apk) containing the Dalvik Executables. On the device itself, each of these applications is executed encapsulated in its own Dalvik Virtual Machine (DVM), a derivate of a conventional Java Virtual Machine (JVM). However, they do not operate completely independent of each other but can interact and exchange information and services with each other based on ``intents'' processed by the operating system. In addition, applications are not restricted to functionalities provided by Java libraries, but can also access native libraries, whose code is executed outside the DVM on the devices processor. For example, an application could natively access low level functionality like \textit{socket} for communication purposes. Though it would still require the permission for internet access, performed messaging could not be traced from purely Java--based solutions. Echtler et al. do not only only perform basic analysis on the encapsulated code, but do also take API calls executing such native code into account. \cite{t02_MobileSandbox}[p. 1810ff]

The core of the solution is based on conventional static and dynamic analysis, adapted to match the mobile environment. The static analysis dissects the application's manifest, which contains information about the granted permissions to access certain device capabilities as well as possible intents and third--party services the app may access. It also decompiles the Dalvik byte code and searches it for potentially dangerous method, e.g. calls to encryption libraries used to obfuscate malicious behaviour, known malign patterns as well as event handlers. The latter will be triggered in the following dynamic analysis. Said analysis is performed using the emulator provided with the android SDK and combining it with already existing solutions from \cite{NEEDED}TaintDroid and \cite{NEEDED} DroidBox to allow tracing and logging of any performed activity performed within the DVM. To enable tracing in native libraries, a modified version of the \textit{ltrace} command is included,a Linux--integrated utility allowing interception of library calls performed by the monitored application, logging all detected calls into a separate file. Since the android emulator natively supports network traffic tracking, these information are also taken into account. A common behaviour for malware on mobile devices is to retain execution until some kind of user interaction has been registered. To simulate said behaviour, the Monkey Runner toolkit is used, which generates random touch events and key presses. The entire analysis process is depicted below.  \cite{t02_MobileSandbox}[p. 1812]

\begin{enumerate}
\item Reset emulator to the initial state.
\item Launch emulator and wait until startup is completed.
\item Install app to be analyzed using adb.
\item Launch app in a new Dalvik VM.
\item Attach ltrace to the VM process running the app.
\item Launch MonkeyRunner to generate simulated UI events.
\item Simulate additional user events like phone calls.
\item Launch a second run of MonkeyRunner.
\item Collect the Dalvik and ltrace log and the network log.
\item Log Analysis
\end{enumerate}


Since in this case, the presented sandboxing system is not used to encapsulate a productively used application but rather to trigger and detect malicious behaviour to classify it as malign, the dimensions of the already well--known criteria are slightly difference. Regarding performance, it is not only necessary to efficiently sandbox the application without affecting its execution, but also to ensure that the entire analysis process is executed in a reasonable time frame. Unfortunately, runtimes for the analysis of a single application using the presented system are between 9 and 14 minutes. However, this is not caused by the final analysis step of the log files, which only takes 10 seconds, but the architecture and tools used to run the application. The initial restart of the emulator, installing the application and running it while triggering user events each takes 2 to 10 minutes, severely increasing performance. Since the system may be used to analyse a multitude of applications at the same time, this drawback may be moderated by running multiple instances of the analysis framework at the same time. In terms of security, the system is ahead of many comparably solutions, since it monitors both regular and native activities. Echtler et al. used the system to analyse a set of known malicious applications and a random set of applications from several Asian app stores and not only correctly classified the first set correctly, but also found 641 malicious apps in the second set. It should be noted though, that they did not conduct any tests regarding a possible false--positive rate. Since the solution is used for malware analysis, detectability of the system plays a significantly higher role. However, most of the features that allow detection base on the fact that the solution utilizes the Android emulator and not the analysis process or method tracing itself. Malicious applications can usually easily detect the emulated nature of their environment by querying build information or the requesting the mobile device's IMSI (International Mobile Subscriber Identity) or IMEI (International Mobile Equipment Identity), which differ from values found on real devices or have known values. To avoid these methods of detection, the authors used a custom build, where these values where changed credible ones if possible. The simulation of user input using Monkey Runner also adds to the authenticity of the system. \cite{t02_MobileSandbox}[p. 1813] 

%Performance has to be measured differently

\subsection{Sandboxing on Apple iOS}
\label{tH02_SandboxProfiles}
%t02_Werthmann

In comparison to the open--source Android operating system, security related research, evaluation as well as extension or improvement of the basic security features is a lot more complex on the closed--source Apple iOS system. This proprietary approach in combination with only a single legitimate app store impede the development and deployment of malicious applications, since all provided applications must adhere to certain guidelines and pass a review performed by Apple, before they can be distributed that way. Nonetheless there were some reported cases of malware attacks successfully performed on the iOS system, especially such regarding access and theft of private and sensitive information --- despite the fact that iOS deploys and runs every application in its own sandbox, similar to Android. Yet these exploits were possible, since Apple used to Apply generic sandbox profiles to any third party application, effectively granting it permission to access contact information, photos, location data, recent web searches and device information. This motivated  Werthman et al. to develop PSiOS, a solution to enforce an individual custom sandbox profile for every third party application, which could be configured by the user. At the time of publication of said work, in 2013, the current version of iOS --- iOS6 --- only supported certain application entitlements, that were granted by its developer to confine the application to a set of privileges, so their solution brought a significant benefit. \cite{t02_Werthmann}[p. 1f] It was also tested towards the already presented criteria and proved to performant enough for everyday use and successfully prevented Spyphone, an application developed specifically to extract sensitive information from iOS devices, from extracting information. It was also successfully applied to popular applications like Facebook, WhatsApp and Instagram (among others). The main drawback of the solution is that it requires a ``jailbroken'' device, which means that certain security and system restrictions are removed. This is necessary to allow PSiOS to modify a single environmental variable  and install a shared library that can access the encapsulated application's code at runtime. This requirement drastically restricts the applicability of the solution, since many users will not be willing to modify there devices. (XXXXXXXXXXXVOIDED WARRANTY??XXXXXXXXXXXX) In addition, a jailbreak itself weakens the devices security and prohibits it form applying any new patches, further increasing security risk. And finally, Apple introduced its own tool for application--specific permissions with iOS 7 in September 2013, only shortly after the release of this work. Nonetheless, their work should be represented in this work, but won't be discussed in more detail. sources!

%http://www.howtogeek.com/177711/ios-has-app-permissions-too-and-theyre-arguably-better-than-androids/
%http://www.howtogeek.com/211623/how-to-manage-app-permissions-on-your-iphone-or-ipad/
%https://www.google.de/webhp?sourceid=chrome-instant&ion=1&espv=2&es_th=1&ie=UTF-8#safe=off&q=ios+jailbreak+security+risks
%http://www.makeuseof.com/tag/4-compelling-security-reasons-jailbreak-iphone-ipad/
%https://de.wikipedia.org/wiki/Apple_iOS
%https://en.wikipedia.org/wiki/IOS_jailbreaking

\section{R\'{e}sum\'{e} and Conclusion}
\label{tH02_Conclusion}
In this paper, several new approaches in sandboxing technology were presented, ranging from advances in..... However, it should be noted that  despite the depicted improvements, there were many other proposals that never left the stage of research, were discontinued or only scarcely available and lacked a broader distribution.

section{ToDo}
  \begin{enumerate}
     \item check if all abbreviations (especially JIT have been introduced and used in full length once
     \item reference the contradiction between the definition of a 'safe sandbox' in AdSafety and ``Dynamic Sandboxing''
	 \item in allen Kapiteln alle Kriterien abgeprüft
	 
  \end{enumerate}




%%
% F�r Flattersatz in Tabellenspalten:
% \newcolumntype{z}{>{\PBS{\raggedright\hspace{0pt}}}p{5cm}}
% statt p{5cm} einfach z verwenden, z.B. \begin{tabular}{|l||c|r|z|}
% F�r graue Tabellenspalten (z.B. zentrierter Text):
% \newcolumntype{g}{>{\columncolor[gray]{0.8}}c} % grau
% \newcolumntype{G}{>{\columncolor[gray]{0.9}}c} % helleres grau
% \begin{tabular}{|l||c|G|g|} oder auch \multicolumn{4}{|g|}{Eine ganze Zeile}
% Aber Achtung: Im xdvi werden graue Zeilen nicht korrekt dargestellt, erst
% im PostScript- oder PDF-Dokument bzw. Ghostview.
%
% /\ /\ /\ /\ /\ /\ /\ /\ /\ /\ /\ /\ /\ /\ /\ /\ /\ /\ /\ /\ /\ /\ /\ /\ /\ 
% -----------------------------------------------------------------------------
% Bitte keinen Text mehr unterhalb dieser Zeile eintragen!!
% -----------------------------------------------------------------------------
%
% --> �blicherweise wird nur die Literatur aufgelistet, die auch referenziert
%   wird. M�chte man auch nichtreferenzierte Literatur einschlie�en, so
%   koennte man dies mit \nocite{<citelabel>} tun (ist jedoch schlechter
%   Stil und soll daher hier nicht gemacht werden).
%\nocite{*}
%   In die folgende Zeile sollte die ben�tigte Literaturdatenbankdatei
%   eingetragen werden (im Normalfall nicht zu �ndern):
\bibliography{tH02_txt}
%
\docend
%%% end of document
